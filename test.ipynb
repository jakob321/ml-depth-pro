{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exjobb/anaconda3/envs/depth-pro/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import depth_pro\n",
    "matplotlib.use(\"qt5agg\")  # For Qt-based interactivity\n",
    "#%matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './checkpoints/depth_pro.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load model and preprocessing transform\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model, transform \u001b[38;5;241m=\u001b[39m \u001b[43mdepth_pro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model_and_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load and preprocess an image.\u001b[39;00m\n",
      "File \u001b[0;32m~/exjobb/eval_models/depth_pro/ml-depth-pro/src/depth_pro/depth_pro.py:135\u001b[0m, in \u001b[0;36mcreate_model_and_transforms\u001b[0;34m(config, device, precision)\u001b[0m\n\u001b[1;32m    125\u001b[0m transform \u001b[38;5;241m=\u001b[39m Compose(\n\u001b[1;32m    126\u001b[0m     [\n\u001b[1;32m    127\u001b[0m         ToTensor(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m     ]\n\u001b[1;32m    132\u001b[0m )\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mcheckpoint_uri \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     missing_keys, unexpected_keys \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mload_state_dict(\n\u001b[1;32m    137\u001b[0m         state_dict\u001b[38;5;241m=\u001b[39mstate_dict, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     )\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unexpected_keys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/depth-pro/lib/python3.9/site-packages/torch/serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/depth-pro/lib/python3.9/site-packages/torch/serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/depth-pro/lib/python3.9/site-packages/torch/serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './checkpoints/depth_pro.pt'"
     ]
    }
   ],
   "source": [
    "# Load model and preprocessing transform\n",
    "model, transform = depth_pro.create_model_and_transforms()\n",
    "model.eval()\n",
    "\n",
    "# Load and preprocess an image.\n",
    "image_path = \"../../../test_images/forest_with_road.jpeg\"\n",
    "image, _, f_px = depth_pro.load_rgb(image_path)\n",
    "image = transform(image)\n",
    "\n",
    "# Run inference.\n",
    "prediction = model.infer(image, f_px=f_px)\n",
    "depth = prediction[\"depth\"]  # Depth in [m].\n",
    "focallength_px = prediction[\"focallength_px\"]  # Focal length in pixels.\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "sequence_containing_x_vals = list(range(0, 100))\n",
    "sequence_containing_y_vals = list(range(0, 100))\n",
    "sequence_containing_z_vals = list(range(0, 100))\n",
    "\n",
    "random.shuffle(sequence_containing_x_vals)\n",
    "random.shuffle(sequence_containing_y_vals)\n",
    "random.shuffle(sequence_containing_z_vals)\n",
    "\n",
    "ax.scatter(sequence_containing_x_vals, sequence_containing_y_vals, sequence_containing_z_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([142, 355])\n",
      "50410\n",
      "tensor(355.9343)\n"
     ]
    }
   ],
   "source": [
    "print(depth.shape)\n",
    "print(depth.shape[0]*depth.shape[1])\n",
    "print(focallength_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Z')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image dimensions\n",
    "image_height, image_width = depth.shape\n",
    "\n",
    "# Generate a meshgrid for pixel coordinates\n",
    "u, v = np.meshgrid(np.arange(image_width), np.arange(image_height))\n",
    "\n",
    "# Normalize pixel coordinates to camera space\n",
    "x_normalized = (u - image_width / 2) / focallength_px\n",
    "y_normalized = (v - image_height / 2) / focallength_px\n",
    "\n",
    "# Back-project to 3D using depth\n",
    "z = depth\n",
    "x = x_normalized * z\n",
    "y = y_normalized * z\n",
    "\n",
    "# Normalize vectors to unit length\n",
    "norm = np.sqrt(x**2 + y**2 + z**2)\n",
    "x_unit = x / norm\n",
    "y_unit = y / norm\n",
    "z_unit = z / norm\n",
    "\n",
    "# Flatten arrays for 3D scatter plot\n",
    "x_unit_flat = x_unit.flatten()\n",
    "y_unit_flat = y_unit.flatten()\n",
    "z_unit_flat = z_unit.flatten()\n",
    "\n",
    "# Plot the points\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(x_unit_flat, y_unit_flat, z_unit_flat, s=1, alpha=0.5)\n",
    "ax.set_title(\"Projection of Unit Vectors\")\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def draw_camera(ax, position, direction, focal_length, up_vector=np.array([0, 1, 0]), size=0.5):\n",
    "    \"\"\"\n",
    "    Draws a 3D representation of a camera in a Matplotlib plot.\n",
    "\n",
    "    Parameters:\n",
    "    - ax: Matplotlib 3D axis to draw the camera on.\n",
    "    - position: np.array, the 3D position of the camera (x, y, z).\n",
    "    - direction: np.array, the direction the camera is pointing.\n",
    "    - focal_length: float, the focal length controlling the size of the frustum.\n",
    "    - up_vector: np.array, the \"up\" direction for the camera (default is [0, 1, 0]).\n",
    "    - size: float, a scaling factor for the size of the camera representation.\n",
    "    \"\"\"\n",
    "    # Normalize the direction and up vector\n",
    "    direction = direction / np.linalg.norm(direction)\n",
    "    up_vector = up_vector / np.linalg.norm(up_vector)\n",
    "    \n",
    "    # Right vector (cross product of direction and up)\n",
    "    right_vector = np.cross(direction, up_vector)\n",
    "    right_vector /= np.linalg.norm(right_vector)\n",
    "    \n",
    "    # Recompute the up vector to ensure orthogonality\n",
    "    up_vector = np.cross(right_vector, direction)\n",
    "    \n",
    "    # Camera corners in 3D space\n",
    "    half_width = size\n",
    "    half_height = size * 0.75\n",
    "    camera_base = position + direction * focal_length  # Camera base center (image plane)\n",
    "    \n",
    "    top_left = camera_base - half_width * right_vector + half_height * up_vector\n",
    "    top_right = camera_base + half_width * right_vector + half_height * up_vector\n",
    "    bottom_left = camera_base - half_width * right_vector - half_height * up_vector\n",
    "    bottom_right = camera_base + half_width * right_vector - half_height * up_vector\n",
    "    \n",
    "    # Draw the frustum (lines from camera position to image plane corners)\n",
    "    for corner in [top_left, top_right, bottom_left, bottom_right]:\n",
    "        ax.plot(\n",
    "            [position[0], corner[0]],\n",
    "            [position[1], corner[1]],\n",
    "            [position[2], corner[2]],\n",
    "            'k-'\n",
    "        )\n",
    "    \n",
    "    # Draw the image plane (rectangle at the base)\n",
    "    ax.plot(\n",
    "        [top_left[0], top_right[0], bottom_right[0], bottom_left[0], top_left[0]],\n",
    "        [top_left[1], top_right[1], bottom_right[1], bottom_left[1], top_left[1]],\n",
    "        [top_left[2], top_right[2], bottom_right[2], bottom_left[2], top_left[2]],\n",
    "        'b-'\n",
    "    )\n",
    "    \n",
    "    # Draw the camera body (a small sphere at the position)\n",
    "    ax.scatter(position[0], position[1], position[2], color='red', s=50, label='Camera')\n",
    "    ax.text(position[0], position[1], position[2], 'Camera', color='red')\n",
    "\n",
    "# Example Usage\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Example camera parameters\n",
    "camera_position = np.array([0, 0, 0])\n",
    "camera_direction = np.array([1, 0, 0])  # Points along the Z-axis\n",
    "focal_length = 1.5\n",
    "\n",
    "draw_camera(ax, camera_position, camera_direction, focal_length)\n",
    "\n",
    "# Set axis labels and limits for better visualization\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "ax.set_xlim(-2, 2)\n",
    "ax.set_ylim(-2, 2)\n",
    "ax.set_zlim(-2, 2)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_camera(\n",
    "    ax,\n",
    "    direction,\n",
    "    focal_length,\n",
    "    center=np.array([0.0, 0.0, 0.0]),\n",
    "    up=np.array([0.0, 1.0, 0.0]),\n",
    "    sensor_width=1.0,\n",
    "    sensor_height=0.75,\n",
    "    color='blue'\n",
    "):\n",
    "    \"\"\"\n",
    "    Draws a simple 3D representation of a camera frustum on a Matplotlib 3D axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : mpl_toolkits.mplot3d.axes3d.Axes3D\n",
    "        A 3D axis from matplotlib for plotting.\n",
    "    direction : array-like of shape (3,)\n",
    "        The camera's viewing (optical) axis vector in 3D space.\n",
    "    focal_length : float\n",
    "        The distance from the camera center to the image plane along `direction`.\n",
    "    center : array-like of shape (3,), optional\n",
    "        The 3D coordinates of the camera center/origin.\n",
    "    up : array-like of shape (3,), optional\n",
    "        A vector indicating the 'up' direction for the camera.\n",
    "    sensor_width : float, optional\n",
    "        The width of the image plane (in some consistent 3D unit).\n",
    "    sensor_height : float, optional\n",
    "        The height of the image plane (in some consistent 3D unit).\n",
    "    color : str, optional\n",
    "        Color for the camera lines.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert inputs to numpy arrays\n",
    "    center = np.array(center, dtype=float).reshape(3)\n",
    "    direction = np.array(direction, dtype=float).reshape(3)\n",
    "    up = np.array(up, dtype=float).reshape(3)\n",
    "\n",
    "    # Normalize the optical axis (z-axis of camera)\n",
    "    z_cam = direction / np.linalg.norm(direction)\n",
    "\n",
    "    # Create an orthogonal coordinate system: find right (x_cam) and up (y_cam).\n",
    "    # We assume 'up' is not perfectly aligned with 'direction'.\n",
    "    x_cam = np.cross(z_cam, up)\n",
    "    x_cam /= np.linalg.norm(x_cam)\n",
    "\n",
    "    y_cam = np.cross(x_cam, z_cam)\n",
    "    y_cam /= np.linalg.norm(y_cam)\n",
    "\n",
    "    # Ensure the basis vectors are orthogonal\n",
    "    assert np.isclose(np.dot(x_cam, y_cam), 0), \"x_cam and y_cam are not orthogonal.\"\n",
    "    assert np.isclose(np.dot(y_cam, z_cam), 0), \"y_cam and z_cam are not orthogonal.\"\n",
    "    assert np.isclose(np.dot(z_cam, x_cam), 0), \"z_cam and x_cam are not orthogonal.\"\n",
    "\n",
    "    # Center of the image plane is focal_length away along the optical axis\n",
    "    plane_center = center + z_cam * focal_length\n",
    "\n",
    "    # Half sizes of the sensor\n",
    "    half_w = sensor_width / 2.0\n",
    "    half_h = sensor_height / 2.0\n",
    "\n",
    "    # Image-plane corners in camera space\n",
    "    # corners at (±half_w, ±half_h) around plane_center\n",
    "    corners = []\n",
    "    for dx in [-half_w, half_w]:\n",
    "        for dy in [-half_h, half_h]:\n",
    "            corner = plane_center + dx * x_cam + dy * y_cam\n",
    "            corners.append(corner)\n",
    "\n",
    "    # Plot lines from the camera center to each corner\n",
    "    for corner in corners:\n",
    "        xs = [center[0], corner[0]]\n",
    "        ys = [center[1], corner[1]]\n",
    "        zs = [center[2], corner[2]]\n",
    "        ax.plot(xs, ys, zs, color=color, linewidth=1.0)\n",
    "\n",
    "    # Plot the rectangle (image plane) by connecting corners in pairs\n",
    "    # We'll connect corners in the order: \n",
    "    # 0 -> 1, 1 -> 3, 3 -> 2, 2 -> 0  (assuming the enumeration below)\n",
    "    # corners: [(-w, -h), (w, -h), (-w, h), (w, h)]\n",
    "    corner_idx_pairs = [(0,1), (1,3), (3,2), (2,0)]\n",
    "    for i1, i2 in corner_idx_pairs:\n",
    "        c1 = corners[i1]\n",
    "        c2 = corners[i2]\n",
    "        ax.plot([c1[0], c2[0]], [c1[1], c2[1]], [c1[2], c2[2]], color=color, linewidth=1.5)\n",
    "\n",
    "    # Optionally, mark the camera center\n",
    "    ax.scatter(center[0], center[1], center[2], color=color, s=40, marker='o')\n",
    "    \n",
    "    # A small label or arrow to show direction\n",
    "    # We'll draw a short arrow along the optical axis for clarity\n",
    "    arrow_scale = focal_length * 0.5  # short arrow in front of camera\n",
    "    arrow_end = center + z_cam * arrow_scale\n",
    "    ax.plot([center[0], arrow_end[0]],\n",
    "            [center[1], arrow_end[1]],\n",
    "            [center[2], arrow_end[2]],\n",
    "            color='red', linewidth=2)\n",
    "    \n",
    "    # Label the arrow as \"direction\"\n",
    "    ax.text(arrow_end[0], arrow_end[1], arrow_end[2], \"Optical Axis\", color='red')\n",
    "    \n",
    "    # Some optional axis labeling\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 9] Bad file descriptor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/depth-pro/lib/python3.9/site-packages/matplotlib/backends/backend_qt.py:166\u001b[0m, in \u001b[0;36m_allow_interrupt_qt.<locals>.prepare_notifier.<locals>._may_clear_sock\u001b[0;34m()\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;129m@sn\u001b[39m\u001b[38;5;241m.\u001b[39mactivated\u001b[38;5;241m.\u001b[39mconnect\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_may_clear_sock\u001b[39m():\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Running a Python function on socket activation gives the interpreter a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# the wakeup.  (We need this in case set_wakeup_fd catches a signal other\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# than SIGINT and we shall continue waiting.)\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m         \u001b[43mrsock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBlockingIOError\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;66;03m# This may occasionally fire too soon or more than once on Windows, so\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;66;03m# be forgiving about reading an empty socket.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 9] Bad file descriptor"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m ax\u001b[38;5;241m.\u001b[39mview_init(elev\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20.\u001b[39m, azim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30.\u001b[39m)\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3D Camera Visualization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/depth-pro/lib/python3.9/site-packages/matplotlib/pyplot.py:612\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    611\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/depth-pro/lib/python3.9/site-packages/matplotlib/backend_bases.py:3553\u001b[0m, in \u001b[0;36m_Backend.show\u001b[0;34m(cls, block)\u001b[0m\n\u001b[1;32m   3551\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m ipython_pylab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive()\n\u001b[1;32m   3552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m-> 3553\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/depth-pro/lib/python3.9/site-packages/matplotlib/backends/backend_qt.py:633\u001b[0m, in \u001b[0;36mFigureManagerQT.start_main_loop\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qapp:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _allow_interrupt_qt(qapp):\n\u001b[0;32m--> 633\u001b[0m         qt_compat\u001b[38;5;241m.\u001b[39m_exec(qapp)\n",
      "File \u001b[0;32m~/anaconda3/envs/depth-pro/lib/python3.9/contextlib.py:126\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/depth-pro/lib/python3.9/site-packages/matplotlib/backend_bases.py:1672\u001b[0m, in \u001b[0;36m_allow_interrupt\u001b[0;34m(prepare_notifier, handle_sigint)\u001b[0m\n\u001b[1;32m   1670\u001b[0m signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handler_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1672\u001b[0m     \u001b[43mold_sigint_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhandler_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Draw two cameras for demonstration:\n",
    "# draw_camera(ax, direction=[0, 0, 1], focal_length=2.0, color='blue')\n",
    "draw_camera(ax, direction=[1, 1, 1], focal_length=3.0,\n",
    "            center=[-2, -2, -1], up=[0, 0, 1], color='green')\n",
    "\n",
    "# Adjust the viewing angle and show the plot\n",
    "ax.view_init(elev=20., azim=30.)\n",
    "plt.title(\"3D Camera Visualization\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depth-pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
